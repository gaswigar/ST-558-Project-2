---
title: "Project 2"
author: "Grant Swigart"
date: "6/22/2020"
output: 
  html_document:
    toc: TRUE

---
  
```{r Automating Report,eval = FALSE, echo = FALSE, message = FALSE}
#This code just automates the report and is run to generate the individual files
library(rmarkdown)
#List of weekdays 
weekday<-c("monday","tuesday","wednesday","thursday","friday","saturday","sunday")
#create filenames
output_file <- paste0(weekday, ".html")
#create a list for each team with just the team name parameter
params = lapply(weekday, FUN = function(x){list(day = x)})
#put into a data frame 
reports <- tibble(output_file, params)
## #need to use x[[1]] to get at elements since tibble doesn't simplify
apply(reports, MARGIN = 1,
      FUN = function(x){
        render(input = 'C:/Users/gswigart/Documents/NCSU/ST 558/Project 2/ST-558-Project-2/README.rmd', 
               output_file = x[[1]], 
               params = x[[2]])
      })


```

# Setup

## Importing

We import the following packages for use thoughout our analysis. 

* tidyverse-Data processing
* GGally-Creating scatterplot/correlation features
* caret-Model contruction
* MASS-Model Selection
* pROC-Plotting ROC curve for exponential regression. 
* stargazer-Making the regression results pretty.  
* knitr- Making pretty tables in R.


```{r setup, include=FALSE,warning=FALSE, message=FALSE}
library(tidyverse)
library(caret)
library(pROC)
library(stargazer)
library(MASS)
library(knitr)

news<-read_csv("C:/Users/gswigart/Documents/NCSU/ST 558/Project 2/ST-558-Project-2/Data/OnlineNewsPopularity.csv") 

```


## Partitioning into Test and Training. 

We filter the data for each day so that we are only viewing output pertaining to this day of the week. We choose to classify a shares binary variable that is 0 for shares<1400 and 1 for shares>1400. We then remove the timedelta and url variables because they are not useful predictors. Afterwards we separate %70 of our data for training and use the remaining observations for testing our models accuracy. 

```{r Partition Data}
params<-list()
params$day<-'monday'
news_day <-news %>%
  filter(get(paste0('weekday_is_',params$day))==1) %>%
  mutate(share_binary=as.factor(ifelse(shares<1400,0,1))) %>%
  dplyr::select(-starts_with('weekday_is'),
                -is_weekend,
                -url,
                -timedelta)


index_train<-unlist(createDataPartition(news_day$share_binary,p=.7))
training<-news_day[index_train,]
testing<-news_day[-index_train,]
```

# Vizualizations and Summary Statistics
You should produce some basic (but meaningful) summary statistics about the training data you are working
with. The general things that the plots describe should be explained but, since we are going to automate
things, there is no need to try and explain particular trends in the plots you see (unless you want to try andautomate that too!)

Lets look into the shares variable and look at its distribution. The first histogram appears to be heavily affected by some outliers in the shares variable. So we remove outliers for the second visualization. The classification threshold is also depicted on the graph. The shares variable has a mean around 1000 shares and appears to be skewed right. 

```{r Shares}
ggplot(data=training,aes(x=shares))+
  geom_histogram(bins = 100)+
  ggtitle('Histogram of Shares of Article')+
  geom_vline(xintercept=1400)


iqr<-IQR(training$shares)
lower<- quantile(training$shares,.25)-1.5*iqr
upper<- quantile(training$shares,.75)+1.5*iqr

training_out_rem<-training %>%
  filter(shares>lower & shares<upper )

ggplot(data=training_out_rem,aes(x=shares)) +
  geom_histogram(bins = 50)+
  ggtitle('Histogram of Shares of Article with Outliers Removed')+
  geom_vline(xintercept=1400)
```


Sharing an article is a two step process. First, the person must click on the article. Some factors that may impact the likeliness of a click are title features, pictures, and the channel type. Lets examine some of the patterns or lack thereof in our data. 

```{r Data Visualizations-Title}

training_out_rem<-training_out_rem %>%
  mutate(channel=ifelse(data_channel_is_lifestyle==1,'lifestyle',
                       ifelse(data_channel_is_entertainment==1,'entertainment',
                       ifelse(data_channel_is_bus==1,'bus',
                       ifelse(data_channel_is_socmed==1,'socmed',
                       ifelse(data_channel_is_tech==1,'tech',
                       ifelse(data_channel_is_world==1,'world','unknown')))))))

ggplot(training_out_rem,aes(x=title_sentiment_polarity,y=shares,color=title_subjectivity))+
         facet_wrap(~channel)+
         geom_jitter()+
         ggtitle('Title Characteristics by Channel')+
         xlab('Title Subjectivity')+
         ylab('Shares')


training_out_rem %>%
  group_by(channel) %>%
  summarise('Average Title Sentiment Polarity'=mean(title_sentiment_polarity),
            'Standard Deviation of Title Sentiment Polarity'=sd(title_sentiment_polarity),
            'Average Title Subjectivity'=mean(title_subjectivity),
            'Standard Deviation of Title Subjectivity'=sd(title_subjectivity)) %>%
  kable()
```

Next lets look at sentiment polarity and subjectivity of the whole article. 

```{r Data Visualizations-Global}
ggplot(training_out_rem,aes(x=global_sentiment_polarity,y=shares,color=global_subjectivity))+
         facet_wrap(~channel)+
         geom_jitter()+
         ggtitle('Title Characteristics by Channel')+
         xlab('Title Subjectivity')+
         ylab('Shares')


training_out_rem %>%
  group_by(channel) %>%
  summarise('Average Global Sentiment Polarity'=mean(global_sentiment_polarity),
            'Standard Deviation of Sentiment Polarity'=sd(global_sentiment_polarity),
            'Average Global Subjectivity'=mean(global_subjectivity),
            'Standard Deviation of Global Subjectivity'=sd(global_subjectivity)) %>%
  kable()
```

Lastly lets see how the number of shares varies by number of videos and images. We filter the number of videos and images so the distributions are more visible. 

```{r Data Visualizations-Grpahics}
ggplot(training_out_rem %>% dplyr::filter(num_videos<5,
                                          num_imgs<10),aes(x=num_imgs,y=shares,color=num_videos))+
         geom_jitter()+
         geom_smooth(method='lm')+
         ggtitle('Videos by Channel')+
         xlab('Videos and Graphics vs Shares')+
         ylab('Shares')

```

# Modeling

## Boosted Tree Model 

We train a boosted tree model below. Repeated 10 fold cross validation was used to select the model parameters below. 

```{r Boosted Tree Model}
 train.control <- trainControl(method = "repeatedcv",
                               number = 10,
                               repeats = 3)

 n.trees<-c(200,300)
 interaction.depth<-c(3,4)
 shrinkage<-c(.05)
 n.minobsinnode<-c(10)
 param_grid<-data.frame(crossing(n.trees,interaction.depth,shrinkage,n.minobsinnode))

 boost_fit = train(share_binary ~ .-shares,
                   data=training,
                   method="gbm",
                   trControl=train.control,
                   distribution="bernoulli",
                   tuneGrid=param_grid,
                   verbose=FALSE)
 
 
 

 print(boost_fit)
 boost_pred <- predict(boost_fit,newdata = dplyr::select(testing, -share_binary))
 conf_boost<-confusionMatrix(boost_pred,testing$share_binary)

 fourfoldplot(conf_boost$table)
 
 data.frame(Accuracy=conf_boost$overall[1],
           Prevision=conf_boost$byClass[5],
           Recall=conf_boost$byClass[6]) %>%
  kable()
 
```

## Regression Model 

It looks like the LDA is not linearly independent from each other. Lets remove LDA_04 and continue. 


```{r Logistic Regression Fit}
#We fit a logistic regression model
glmFit <- glm(share_binary ~ . -LDA_04-shares, data = training, family = "binomial")
plot(glmFit,which = 4, id.n = 5)

glmFit <- glm(share_binary ~ . -LDA_04-shares, data = training %>% filter(!(row_number() %in% c(630)), family = "binomial")
plot(glmFit)
summary(glmFit)


step.model <- glmFit %>% stepAIC(trace = FALSE)



summary(glmFit)
glm_pred <- predict(step.model,newdata = dplyr::select(testing, -share_binary),type = "response")
roc_obj <- roc(testing$share_binary, glm_pred)
plot(roc_obj)
thresh<-coords(roc_obj, "best", "threshold")
```


```{r model comparison, results='asis'}
stargazer(glmFit,step.model)
```


```{r Logistic Regression Results}
conf_exp<-confusionMatrix(data = as.factor(as.numeric(glm_pred>thresh$threshold)), reference = testing$share_binary)
fourfoldplot(conf_exp$table)
data.frame(Accuracy=conf_exp$overall[1],
           Prevision=conf_exp$byClass[5],
           Recall=conf_exp$byClass[6]) %>%
  kable()
```

# Comparison of Models

```{r comparison of results }
accuracy<-c(conf_boost$overall[1],conf_exp$overall[1])
precision<-c(conf_boost$byClass[5],conf_exp$byClass[5])
recall<-c(conf_boost$byClass[6],conf_exp$byClass[6])

model<-c('Boosted Tree','Exponential Regression')
data.frame(model,accuracy,precision,recall) %>% kable()
```
 
 
 Hlavac, Marek (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables.
 R package version 5.2.2. https://CRAN.R-project.org/package=stargaze
